{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "407c75b4-b15a-4a32-bf6b-028aa54502ea",
   "metadata": {},
   "source": [
    "# Test saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc3082fb-e9d0-4d9f-8331-46556f5178fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de5d66b4-1b4b-43f1-b03c-aa63de78ac01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "data_dir = pathlib.Path(\"/home/theorist/Desktop/Programming/ML/capstone-1/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b3d0f74-35ce-4e31-a472-ab9c42253991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1799"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = data_dir / \"train\" / \"images\"\n",
    "data_dir\n",
    "\n",
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "image_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2092ee7-86f1-4a59-a2aa-454f94051751",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 180\n",
    "img_width = 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3bed7431-66b5-40d3-816d-08f3098349e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1799 files belonging to 6 classes.\n",
      "Using 1440 files for training.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd377c45-f928-4e67-b74d-062a42edd7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1799 files belonging to 6 classes.\n",
      "Using 359 files for validation.\n"
     ]
    }
   ],
   "source": [
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60cab8c9-d4d7-48ef-ab4e-709210e47fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['crazing', 'inclusion', 'patches', 'pitted_surface', 'rolled-in_scale', 'scratches']\n"
     ]
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2e001e8-60b2-44a5-b5cd-19b0b91f9493",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"steel_defect_clf.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e5aa25b8-0b69-43ba-832e-615f3006a975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "This image most likely belongs to crazing with a 84.28 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "crazing_path = pathlib.Path(\"/home/theorist/Desktop/Programming/ML/capstone-1/crazing_19.jpg\")\n",
    "\n",
    "img = tf.keras.utils.load_img(\n",
    "    crazing_path, target_size=(img_height, img_width)\n",
    ")\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24a7ecb-31bb-4522-a7b8-94d7b1075c76",
   "metadata": {},
   "source": [
    "# TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "24e9639a-b7c8-457d-b9df-ad4316e0a0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpc7fjr94r/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpc7fjr94r/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmpc7fjr94r'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 180, 180, 3), dtype=tf.float32, name='input_layer_3')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 6), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  123728936969216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123728937016608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123728937024880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123728937021184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123728937011504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123728937175520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123728937185200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123728937389920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123728937188192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123728937392736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1736757436.615625   40119 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1736757436.615637   40119 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "2025-01-13 14:07:16.615743: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpc7fjr94r\n",
      "2025-01-13 14:07:16.616226: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2025-01-13 14:07:16.616236: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmpc7fjr94r\n",
      "2025-01-13 14:07:16.620957: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2025-01-13 14:07:16.659898: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmpc7fjr94r\n",
      "2025-01-13 14:07:16.668638: I tensorflow/cc/saved_model/loader.cc:466] SavedModel load for tags { serve }; Status: success: OK. Took 52897 microseconds.\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b72ed2b8-034f-4ee8-ac3b-df9d7afd5964",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cb629306-7574-4cbe-8e88-4671854186bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " model.tflite\t\t 'Steel Industry.ipynb'\n",
      " steel_defect_clf.keras   tflite_config.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ea91fbf7-7a0c-40b0-8067-b73c0b6c5dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_MODEL_FILE_PATH = 'model.tflite'\n",
    "interpreter = tf.lite.Interpreter(model_path=TF_MODEL_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "262e366c-a2db-4208-82c8-d78b049337c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'serving_default': {'inputs': ['input_layer_3'], 'outputs': ['output_0']}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter.get_signature_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "57f833eb-3874-4508-a37a-d1f31a67ecc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.lite.python.interpreter.SignatureRunner at 0x7087e21ac760>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_lite = interpreter.get_signature_runner('serving_default')\n",
    "classify_lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fc219db2-971c-486a-a7b9-4308aa03c65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lite = classify_lite(input_layer_3=img_array)['output_0']\n",
    "score_lite = tf.nn.softmax(predictions_lite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c50eae9d-fea4-447b-8b55-5e76c3a5e18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to crazing with a 84.28 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score_lite)], 100 * np.max(score_lite))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "318ca21c-7e66-4df0-b580-f39ea3acd557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5258789e-05\n"
     ]
    }
   ],
   "source": [
    "print(np.max(np.abs(predictions - predictions_lite)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e62dc0f0-fa0c-484b-904b-879ca3854e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15961432"
     ]
    }
   ],
   "source": [
    "!stat --printf=\"%s\" model.tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "637ef90c-d0b9-4c57-aa20-024b0dbe1956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47933199"
     ]
    }
   ],
   "source": [
    "!stat --printf=\"%s\" steel_defect_clf.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd991d2-4c93-461e-99fa-c48eff83641f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML-venv",
   "language": "python",
   "name": "ml-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
